---
title: "Replication of \"Rapid Word Learning Under Uncertainty via Cross-Situational Statistics\" (2007 Psychological Science)"
author: "Allison Park, Yawen Dong, Junyi Hui & Pengjia Cui"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

[**The github repo for the full project**](https://github.com/ucsd-psych201a/yu2007/tree/main)

[**The github repo of Pengjia Cui**](https://github.com/Amethystium-321E1/yu2007)

## Introduction

The stimuli will consist of 54 unfamiliar objects paired with 54 pseudowords, divided into sets of 18 word-referent pairs. Pseudowords will be generated to sound like plausible English words but lack meaning, while the objects will be unfamiliar to prevent prior knowledge from influencing learning.

Participants will be presented with multiple trials in three conditions: 2 words with 2 objects, 3 words with 3 objects, and 4 words with 4 objects. In each trial, words and referents are shown simultaneously without clues linking them, requiring participants to learn the correct word-referent pairings by tracking co-occurrences across trials. After the learning phase, participants will take a forced-choice test to identify the correct referents for each word.

The main challenge will be ensuring the ambiguity of each trial while maintaining statistical information across trials, along with controlling the timing and stimuli presentation to match the original study.

The primary challenge lies in replicating the complex design, ensuring that each trial maintains ambiguity while preserving cross-trial statistical regularities that allow participants to learn the correct word-referent pairings. Additionally, ensuring accurate timing and stimuli presentation, consistent with the original study, will be crucial for a valid replication.

The original paper can be accessed via [DOI](https://doi.org/10.1111/j.1467-9280.2007.01915.x), and the replication materials are available in the [repository here](https://github.com/InterFusion-0053/yu2007/).

## Methods

### Power Analysis

### Planned Sample

The planned sample size is set at 38 participants based on power analysis, with a termination rule allowing for additional recruitment if data exclusions reduce the usable sample below 30. Participants will be recruited from a university student pool. The sampling frame is limited to native English-speaking adults aged 18 to 35, and participants will receive monetary compensation (by Yu & Simth 2007, 7\$ each person). No preselection rules are applied beyond these demographic and language criteria.

### Materials

All materials will follow the original article’s description precisely. As stated in the article, “the stimuli were slides containing pictures of uncommon objects (We'll use JsPsysch for that) paired with auditorily presented pseudowords.(18 images and 18 wav files on [Google Drive](https://drive.google.com/drive/folders/1qu7-ZgbhbMWOzZQxvXnVMCdSLIasc-o8))” The pseudowords are computer-generated to maintain phonotactic probability in English. The word-referent pairs, experimental setup, and conditions (2x2, 3x3, and 4x4) will be recreated according to the original specifications, with each pair presented six times across trials.

### Procedure

The procedure will follow Yu & Smith (2007) with minimal modification: “Each trial began with the simultaneous visual presentation of the referents on a computer monitor. The names were then presented auditorily over the computer’s speakers.” As in the original study, no additional cues will be provided to suggest word-object pairings within individual trials, and participants will complete a 4-alternative forced-choice test following each condition.

### Analysis Plan

The analysis plan will replicate the original study’s strategy closely. Data cleaning rules include removing trials with response times exceeding three standard deviations from the participant’s mean or below 200 ms. Data exclusions will follow the criteria set forth in the “Exclusions” section of this protocol. We will calculate the mean accuracy for each participant in each condition and conduct a repeated-measures ANOVA to test for differences across the 2x2, 3x3, and 4x4 conditions.

The primary analysis of interest is the repeated-measures ANOVA, testing whether accuracy varies significantly across conditions with different ambiguity levels. Additional exploratory analyses will examine potential learning patterns across trials.

### Differences from Original Study

Our study aims to mirror the original as closely as possible. However, differences may arise from using a different sample frame (our university student pool) and potential minor procedural adjustments due to updated software. Based on the literature, these differences are not expected to substantially impact the effect.

### Methods Addendum (Post Data Collection)

*(Comment this section out prior to final report with data collection)*

#### Actual Sample

Expected to be 38 participants.

#### Differences from pre-data collection methods plan

None.

## Design Overview

1.  How many factors were manipulated?

-   The trial ambiguity (2x2 3x3 4x4)

2.  How many measures were taken?

-   Two, the accuracy and response time

3.  Did it use a within-participants or between-participants design?

-   within-participants

4.  Were measures repeated?

-   Yes, repeated measure for each level ambiguity

5.  What would have been the consequence of changing one of these decisions? (e.g. moving from within to between participants). Could it have been either way?

-   Since the sample isn't large, conducting between-participants design could cause higher variation

6.  Were steps taken to reduce demand characteristics?

-   Yes, we use pseudo words, computer generated pronunciation and uncommon images

7.  How would you critique the design?

-   The sample size should be larger

8.  Can you think of any potential confounds to the study?

-   The backgrounds of participants, say if someone is multi-lingual. And the syllables of the words may differ.

9.  Do you see any limitations to generalizability?

-   The sample comes from 18\~35 years old adults. Poor generalizability expected on younger groups.

## Results

[Paradigm](https://ucsd-psych201a.github.io/yu2007/coding.html)

### Data preparation

Data preparation will follow the steps outlined in the Analysis Plan to ensure consistent and accurate processing. The following steps will be applied:

1.  **Data Cleaning**:
    -   Exclude trials with response times that exceed three standard deviations from each participant’s mean RT or are under 200 ms (The criteria may need to be slightly changed). Such trials are flagged as outliers, indicating inattentive or anticipatory responses.
2.  **Calculating Mean Accuracy**:
    -   Calculate the mean accuracy score for each participant in each condition (2x2, 3x3, and 4x4). These scores will be the dependent variable for ANOVA.
3.  **Exclusion of Participants**:
    -   Apply participant exclusion criteria as specified in the Exclusions section (The criteria may need to be slightly changed).
4.  **Final Dataset Creation**:
    -   The cleaned data will include mean accuracy scores per condition for each participant who meets the inclusion criteria. This dataset will be used for the confirmatory analysis.

### Data cleaning

```{r}
library(dplyr)
df_list <- list()
file_list <- list.files("raw_data/", pattern = "\\.csv$", full.names = TRUE)

for (i in seq_along(file_list)) {
  df <- read.csv(file_list[i])
  df <- df[, (ncol(df) - 4):ncol(df)]
  df <- na.omit(df)
  df$respondent <- i - 1
  df_list[[i]] <- df
}

data <- bind_rows(df_list)
data$correct <- tolower(data$correct) == "true"
data
```

```{r include=F}
library(ggplot2)
library(tidyr)
library(tidyverse)
library(effsize)
library(pwr)
library(reticulate)


# Filter trials with extreme response times
mean_rt <- mean(data$response_time, na.rm = TRUE)
sd_rt <- sd(data$response_time, na.rm = TRUE)
data <- subset(data, response_time >= (mean_rt - 3 * sd_rt) & response_time <= (mean_rt + 3 * sd_rt))

# Check participant performance above chance level
participant_accuracy <- data %>%
  group_by(respondent) %>%
  summarize(accuracy = mean(correct))

# Keep participants above chance (50% for binary tasks)
data <- data[data$respondent %in% participant_accuracy$respondent[participant_accuracy$accuracy > 0.5], ]

```

### Confirmatory Analysis

We will perform a **repeated-measures ANOVA** to assess differences in accuracy across the three conditions: 2x2, 3x3, and 4x4. This test will evaluate whether the degree of within-trial ambiguity significantly affects participants’ accuracy in learning word-referent pairings.

The analysis steps are as follows:

1.  **Overall Accuracy**

```{r}
# Calculate overall accuracy
overall_accuracy <- mean(data$correct, na.rm = TRUE)
print(paste("Overall Accuracy: ", round(overall_accuracy * 100, 2), "%"))
```

We now only finished the part for 2 by 2 condition. The results are currently based on this term. The results are slightly higher than the original paper. More strict control may need to be implemented.

2.  **Image-Specific Accuracy**

```{r}
img_acc <- data %>%
  group_by(correct_image) %>%
  summarize(accuracy = mean(correct, na.rm = TRUE))

ggplot(img_acc, aes(x = correct_image, y = accuracy)) +
  geom_line(color = "grey",linewidth = 1) + 
  geom_point(size = 1) +
  scale_x_continuous(breaks = seq(min(data$correct_image), max(data$correct_image), 1)) +
  labs(x = "Per Image", y = "Accuracy")
```

The accuracy of each image varies. Img 15 shows 100% accuracy on every participant; this may be due to the pseudoword of this picture sounds like a combination of a few letters. The other results match our expection.

3.  **Response Time by Correctness**

```{r}
response_time_summary <- data %>%
  group_by(correct) %>%
  summarize(
    mean_response_time = mean(response_time, na.rm = TRUE),
    median_response_time = median(response_time, na.rm = TRUE),
    sd_response_time = sd(response_time, na.rm = TRUE)
  )
print(response_time_summary)

ggplot(data, aes(x = factor(correct, labels = c("Incorrect", "Correct")), y = response_time)) +
  geom_boxplot(fill = "skyblue3", alpha = 0.7) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 3, color = "red") +
  labs(
    title = "Response Time by Correctness",
    x = "Response Accuracy",
    y = "Response Time"
  ) +
  theme_minimal()
```

The response time of correct answers is significantly lower than incorrect ones, showing hesitation as expected.

4.  **T-test**

```{r}
# Conduct t-test for response times
t_test <- t.test(response_time ~ correct, data = data)
t_test
```

We here have a p-value of 0.02, which cannot reject the null hypothesis. During the writing of this report another result was recorded but was not counted in the above coding. If we count the last result, p-value would be approximately 0.0005357, since the last participant hit the full score. In the meantime, it shows that a much smaller sample than planned would largely affect the result.

5.  **Power analysis**

    ```{r}
    cohens_d_result <- cohen.d(data$response_time ~ data$correct)
    print(cohens_d_result)


    pwr_result <- pwr.t.test(d = 0.5382748, sig.level = 0.05, power = 0.80, type = "two.sample")
    print(pwr_result)

    ```

    Based on the pilot test, we observed a medium effect size of 0.54 in the 2×2 condition. A power analysis using G\*Power was conducted for a two-sample t-test with a significance level of $\alpha$=0.05 and a desired power of 0.80. The analysis revealed that a minimum of 56 participants per group would be required to achieve adequate statistical power for detecting this effect size. It’s important to note that these estimates are derived solely from the 2×2 condition, which may limit their generalizability.

*Side-by-side graph with original graph is ideal here*

### Links

-   [html file](https://github.com/ucsd-psych201a/yu2007/tree/main/stimuli)
-   [stimuli list](https://github.com/ucsd-psych201a/yu2007/blob/main/coding_test.html)

### Exploratory analyses

Any follow-up analyses desired (not required).

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt. None of these need to be long.
